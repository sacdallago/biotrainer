config:
  auto_resume: false
  batch_size: 128
  bootstrapping_iterations: 30
  cross_validation_config:
    method: hold_out
    choose_by: loss
  device: cpu
  disable_pytorch_compile: true
  dropout_rate: 0.25
  embedder_name: one_hot_encoding
  epsilon: 0.001
  external_writer: tensorboard
  ignore_file_inconsistencies: false
  input_file: /home/sebie/PycharmProjects/biotrainerFork/examples/residue_to_class/input.fasta
  learning_rate: 0.001
  limited_sample_size: -1
  log_dir: 
    /home/sebie/PycharmProjects/biotrainerFork/examples/residue_to_class/output/CNN/one_hot_encoding
  loss_choice: cross_entropy_loss
  model_choice: CNN
  num_epochs: 200
  optimizer_choice: adam
  output_dir: /home/sebie/PycharmProjects/biotrainerFork/examples/residue_to_class/output
  patience: 10
  protocol: residue_to_class
  sanity_check: true
  save_split_ids: false
  seed: 42
  shuffle: true
  use_class_weights: true
  use_half_precision: false
  validate_input: true
database_type: Protein
derived_values:
  biotrainer_version: 1.0.0
  class_int2str:
    0: C
    1: D
    2: E
    3: F
    4: V
  class_str2int:
    C: 0
    D: 1
    E: 2
    F: 3
    V: 4
  computed_class_weights:
    0: 2.6666667461395264
    1: 0.6666666865348816
    2: 1.0
    3: 1.0
    4: 0.8888888955116272
  model_hash: c172f3bc0f91f6bf
  n_classes: 5
  n_features: 21
  n_testing_ids: 1
  pipeline_elapsed_time: 3.3591139079981076
  pipeline_end_time: '2025-06-26T12:21:38.733890'
  pipeline_start_time: '2025-06-26T12:21:35.374776'
  training_elapsed_time: 2.555912886000442
training_results:
  hold_out:
    n_training_ids: 1
    n_validation_ids: 1
    split_hyper_params: {}
    n_free_parameters: 5861
    start_time: '2025-06-26T12:21:35.383560'
    end_time: '2025-06-26T12:21:37.935195'
    elapsed_time: 2.551625447002152
    best_training_epoch_metrics:
      epoch: 84
      training:
        loss: 0.18558017909526825
        accuracy: 1.0
        macro-precision: 1.0
        micro-precision: 1.0
        '- precision class 0': 1.0
        '- precision class 1': 1.0
        '- precision class 2': 0.0
        '- precision class 3': 0.0
        '- precision class 4': 1.0
        macro-recall: 1.0
        micro-recall: 1.0
        '- recall class 0': 1.0
        '- recall class 1': 1.0
        '- recall class 2': 0.0
        '- recall class 3': 0.0
        '- recall class 4': 1.0
        macro-f1_score: 1.0
        micro-f1_score: 1.0
        '- f1_score class 0': 1.0
        '- f1_score class 1': 1.0
        '- f1_score class 2': 0.0
        '- f1_score class 3': 0.0
        '- f1_score class 4': 1.0
        spearmans-corr-coeff: 0.9999998807907104
        matthews-corr-coeff: 1.0
      validation:
        loss: 1.059759497642517
        accuracy: 0.3333333432674408
        macro-precision: 0.5
        micro-precision: 0.3333333432674408
        '- precision class 0': 0.0
        '- precision class 1': 1.0
        '- precision class 2': 0.0
        '- precision class 3': 0.0
        '- precision class 4': 0.0
        macro-recall: 0.1666666716337204
        micro-recall: 0.3333333432674408
        '- recall class 0': 0.0
        '- recall class 1': 0.3333333432674408
        '- recall class 2': 0.0
        '- recall class 3': 0.0
        '- recall class 4': 0.0
        macro-f1_score: 0.25
        micro-f1_score: 0.3333333432674408
        '- f1_score class 0': 0.0
        '- f1_score class 1': 0.5
        '- f1_score class 2': 0.0
        '- f1_score class 3': 0.0
        '- f1_score class 4': 0.0
        spearmans-corr-coeff: 0.0
        matthews-corr-coeff: 0.0
    training_loss:
      '0': 1.6693501472473145
      '1': 1.650396704673767
      '2': 1.6439720392227173
      '3': 1.5845987796783447
      '4': 1.5926543474197388
      '5': 1.5735441446304321
      '6': 1.5431081056594849
      '7': 1.5657017230987549
      '8': 1.537536382675171
      '9': 1.5151127576828003
      '10': 1.4826921224594116
      '11': 1.524902105331421
      '12': 1.4650108814239502
      '13': 1.4216569662094116
      '14': 1.4484068155288696
      '15': 1.3995811939239502
      '16': 1.3952255249023438
      '17': 1.402337670326233
      '18': 1.363242745399475
      '19': 1.3474977016448975
      '20': 1.3229080438613892
      '21': 1.3543510437011719
      '22': 1.2499884366989136
      '23': 1.299497365951538
      '24': 1.235678791999817
      '25': 1.189746618270874
      '26': 1.1449822187423706
      '27': 1.209301471710205
      '28': 1.0873569250106812
      '29': 1.1066477298736572
      '30': 1.1253336668014526
      '31': 1.0693844556808472
      '32': 1.0117636919021606
      '33': 1.016241192817688
      '34': 0.9633303284645081
      '35': 0.8928214907646179
      '36': 0.9949941039085388
      '37': 0.8624929189682007
      '38': 0.833806037902832
      '39': 0.7941717505455017
      '40': 0.8239498138427734
      '41': 0.731784462928772
      '42': 0.7660256624221802
      '43': 0.7775270938873291
      '44': 0.6642673015594482
      '45': 0.6488196849822998
      '46': 0.6682573556900024
      '47': 0.6395348906517029
      '48': 0.5803272724151611
      '49': 0.5311182737350464
      '50': 0.5909075736999512
      '51': 0.4823937714099884
      '52': 0.5183343887329102
      '53': 0.43519356846809387
      '54': 0.5401352047920227
      '55': 0.38984861969947815
      '56': 0.42106735706329346
      '57': 0.3849603831768036
      '58': 0.44139909744262695
      '59': 0.3804428279399872
      '60': 0.36735889315605164
      '61': 0.3926309645175934
      '62': 0.33363428711891174
      '63': 0.27550655603408813
      '64': 0.3485362231731415
      '65': 0.27082571387290955
      '66': 0.2948378920555115
      '67': 0.3061317503452301
      '68': 0.2999364137649536
      '69': 0.1958903670310974
      '70': 0.2762104272842407
      '71': 0.22198596596717834
      '72': 0.22140036523342133
      '73': 0.16156935691833496
      '74': 0.2510189116001129
      '75': 0.15530437231063843
      '76': 0.14412017166614532
      '77': 0.21183860301971436
      '78': 0.1617695838212967
      '79': 0.14513325691223145
      '80': 0.1526758223772049
      '81': 0.19291622936725616
      '82': 0.23429380357265472
      '83': 0.12133131176233292
      '84': 0.18558017909526825
      '85': 0.09706676751375198
      '86': 0.11855829507112503
      '87': 0.13424800336360931
      '88': 0.16095156967639923
      '89': 0.10670148581266403
      '90': 0.13632585108280182
      '91': 0.12989023327827454
      '92': 0.09974504262208939
      '93': 0.1315639168024063
      '94': 0.10551842302083969
      '95': 0.1226000040769577
    validation_loss:
      '0': 1.6013376712799072
      '1': 1.6259313821792603
      '2': 1.6083498001098633
      '3': 1.5959787368774414
      '4': 1.5883972644805908
      '5': 1.587745189666748
      '6': 1.5761582851409912
      '7': 1.5840256214141846
      '8': 1.5632050037384033
      '9': 1.5548462867736816
      '10': 1.555487871170044
      '11': 1.5400253534317017
      '12': 1.552158236503601
      '13': 1.5589957237243652
      '14': 1.5407721996307373
      '15': 1.5377745628356934
      '16': 1.5525861978530884
      '17': 1.5224069356918335
      '18': 1.501172661781311
      '19': 1.5285627841949463
      '20': 1.5158569812774658
      '21': 1.5050067901611328
      '22': 1.4823403358459473
      '23': 1.489363431930542
      '24': 1.4963030815124512
      '25': 1.5002435445785522
      '26': 1.4716360569000244
      '27': 1.4973392486572266
      '28': 1.4595575332641602
      '29': 1.4505701065063477
      '30': 1.4745312929153442
      '31': 1.4495570659637451
      '32': 1.4446054697036743
      '33': 1.4561277627944946
      '34': 1.4043304920196533
      '35': 1.4164438247680664
      '36': 1.3962253332138062
      '37': 1.4259321689605713
      '38': 1.4299383163452148
      '39': 1.4108226299285889
      '40': 1.419845461845398
      '41': 1.3815196752548218
      '42': 1.3816274404525757
      '43': 1.3906874656677246
      '44': 1.3624167442321777
      '45': 1.3656678199768066
      '46': 1.3297688961029053
      '47': 1.3250700235366821
      '48': 1.3335046768188477
      '49': 1.317781686782837
      '50': 1.2906312942504883
      '51': 1.335958480834961
      '52': 1.327301263809204
      '53': 1.298471450805664
      '54': 1.284450650215149
      '55': 1.2931017875671387
      '56': 1.3088006973266602
      '57': 1.2819569110870361
      '58': 1.3014512062072754
      '59': 1.2627160549163818
      '60': 1.2174839973449707
      '61': 1.254464030265808
      '62': 1.2556817531585693
      '63': 1.2567213773727417
      '64': 1.2594795227050781
      '65': 1.2623223066329956
      '66': 1.2239420413970947
      '67': 1.225056767463684
      '68': 1.2547518014907837
      '69': 1.206876277923584
      '70': 1.1946872472763062
      '71': 1.2053698301315308
      '72': 1.1900074481964111
      '73': 1.1856491565704346
      '74': 1.2130520343780518
      '75': 1.1312309503555298
      '76': 1.1651967763900757
      '77': 1.1703054904937744
      '78': 1.1659815311431885
      '79': 1.1681933403015137
      '80': 1.1850793361663818
      '81': 1.152148962020874
      '82': 1.1481257677078247
      '83': 1.1660486459732056
      '84': 1.059759497642517
      '85': 1.1119242906570435
      '86': 1.1623666286468506
      '87': 1.0985835790634155
      '88': 1.1577194929122925
      '89': 1.1490339040756226
      '90': 1.1463046073913574
      '91': 1.1419925689697266
      '92': 1.1560472249984741
      '93': 1.1198757886886597
      '94': 1.1211011409759521
      '95': 1.161659598350525
test_results:
  test:
    metrics:
      loss: 2.628438949584961
      accuracy: 0.2857142984867096
      macro-precision: 0.11428572237491608
      micro-precision: 0.2857142984867096
      '- precision class 0': 0.0
      '- precision class 1': 0.5714285969734192
      '- precision class 2': 0.0
      '- precision class 3': 0.0
      '- precision class 4': 0.0
      macro-recall: 0.08888889104127884
      micro-recall: 0.2857142984867096
      '- recall class 0': 0.0
      '- recall class 1': 0.4444444477558136
      '- recall class 2': 0.0
      '- recall class 3': 0.0
      '- recall class 4': 0.0
      macro-f1_score: 0.10000000149011612
      micro-f1_score: 0.2857142984867096
      '- f1_score class 0': 0.0
      '- f1_score class 1': 0.5
      '- f1_score class 2': 0.0
      '- f1_score class 3': 0.0
      '- f1_score class 4': 0.0
      spearmans-corr-coeff: -0.054820869117975235
      matthews-corr-coeff: -0.06608480960130692
    bootstrapping:
      results:
        accuracy:
          mean: 0.28564453125
          error: 0.0
        macro-precision:
          mean: 0.1142578125
          error: 0.0
        micro-precision:
          mean: 0.28564453125
          error: 0.0
        '- precision class 0':
          mean: 0.0
          error: 0.0
        '- precision class 1':
          mean: 0.5712890625
          error: 0.0
        '- precision class 2':
          mean: 0.0
          error: 0.0
        '- precision class 3':
          mean: 0.0
          error: 0.0
        '- precision class 4':
          mean: 0.0
          error: 0.0
        macro-recall:
          mean: 0.0888671875
          error: 0.0
        micro-recall:
          mean: 0.28564453125
          error: 0.0
        '- recall class 0':
          mean: 0.0
          error: 0.0
        '- recall class 1':
          mean: 0.4443359375
          error: 0.0
        '- recall class 2':
          mean: 0.0
          error: 0.0
        '- recall class 3':
          mean: 0.0
          error: 0.0
        '- recall class 4':
          mean: 0.0
          error: 0.0
        macro-f1_score:
          mean: 0.0999755859375
          error: 0.0
        micro-f1_score:
          mean: 0.28564453125
          error: 0.0
        '- f1_score class 0':
          mean: 0.0
          error: 0.0
        '- f1_score class 1':
          mean: 0.5
          error: 0.0
        '- f1_score class 2':
          mean: 0.0
          error: 0.0
        '- f1_score class 3':
          mean: 0.0
          error: 0.0
        '- f1_score class 4':
          mean: 0.0
          error: 0.0
        spearmans-corr-coeff:
          mean: -0.0548095703125
          error: 0.0
        matthews-corr-coeff:
          mean: -0.06610107421875
          error: 0.0
      iterations: 30
      sample_size: 1
      confidence_level: 0.05
    test_baselines:
      random_model:
        results:
          accuracy:
            mean: 0.28564453125
            error: 0.0
          macro-precision:
            mean: 0.1600341796875
            error: 0.0
          micro-precision:
            mean: 0.28564453125
            error: 0.0
          '- precision class 0':
            mean: 0.0
            error: 0.0
          '- precision class 1':
            mean: 0.0
            error: 0.0
          '- precision class 2':
            mean: 0.300048828125
            error: 0.0
          '- precision class 3':
            mean: 0.5
            error: 0.0
          '- precision class 4':
            mean: 0.0
            error: 0.0
          macro-recall:
            mean: 0.300048828125
            error: 0.0
          micro-recall:
            mean: 0.28564453125
            error: 0.0
          '- recall class 0':
            mean: 0.0
            error: 0.0
          '- recall class 1':
            mean: 0.0
            error: 0.0
          '- recall class 2':
            mean: 1.0
            error: 0.0
          '- recall class 3':
            mean: 0.5
            error: 0.0
          '- recall class 4':
            mean: 0.0
            error: 0.0
          macro-f1_score:
            mean: 0.1922607421875
            error: 0.0
          micro-f1_score:
            mean: 0.28564453125
            error: 0.0
          '- f1_score class 0':
            mean: 0.0
            error: 0.0
          '- f1_score class 1':
            mean: 0.0
            error: 0.0
          '- f1_score class 2':
            mean: 0.46142578125
            error: 0.0
          '- f1_score class 3':
            mean: 0.5
            error: 0.0
          '- f1_score class 4':
            mean: 0.0
            error: 0.0
          spearmans-corr-coeff:
            mean: 0.1036376953125
            error: 0.0
          matthews-corr-coeff:
            mean: 0.2296142578125
            error: 0.0
        iterations: 30
        sample_size: 1
        confidence_level: 0.05
    sanity_check_warnings:
    - Model is only predicting [1, 4, 0, 1, 4, 4, 1, 1, 4, 1, 4, 1, 1, 4] for all
      test samples!
predictions: {}
