{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This notebook demonstrates how to add arbitrary numerical values from a csv file to an existing embedding file\n",
    "# We will use embeddings on a sequence level (reduced embeddings)\n",
    "# We concatenate to existing one_hot_encoding embeddings\n",
    "# The sequences have ids [Seq1, Seq2, Seq3, Seq4], like the example for sequence_to_class\n",
    "\n",
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Load existing reduced embedding files\n",
    "reduced_embeddings_one_hot_path = \"../example_files/reduced_embeddings_file_one_hot_encoding.h5\"\n",
    "reduced_embeddings_one_hot_file = h5py.File(reduced_embeddings_one_hot_path, 'r', rdcc_nbytes=1024 ** 2 * 4000,\n",
    "                                            rdcc_nslots=1e7)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Read values from csv\n",
    "values_dict = {}\n",
    "with open(\"../example_files/arbitrary_values.csv\", \"r\") as csv_file:\n",
    "    lines = csv_file.readlines()[1:]\n",
    "    for line in lines:\n",
    "        seq_id = line.split(\",\")[0]\n",
    "        values = [float(value) for value in line.split(\",\")[1].replace(\"[\", \"\").replace(\"]\", \"\").split(\";\")]\n",
    "        values_dict[seq_id] = values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Add values to new file:\n",
    "# 1. Create a new file\n",
    "reduced_output_embeddings_path = \"enhanced_one_hot_embeddings.h5\"\n",
    "# 2. Get embedding dimension\n",
    "one_hot_dim = reduced_embeddings_one_hot_file[\"0\"].shape[0]\n",
    "\n",
    "with h5py.File(reduced_output_embeddings_path, \"w\") as reduced_output_embeddings_file:\n",
    "    # 3. Save one_hot_encoding values in new file with extended shape\n",
    "    for idx, embedding in reduced_embeddings_one_hot_file.items():\n",
    "        original_sequence_id = reduced_embeddings_one_hot_file[idx].attrs[\"original_id\"]\n",
    "        appendix_dim = len(values_dict[original_sequence_id])\n",
    "        reduced_output_embeddings_file.create_dataset(idx, data=embedding, compression=\"gzip\", chunks=True,\n",
    "                                                      maxshape=(one_hot_dim + appendix_dim))\n",
    "        reduced_output_embeddings_file[idx].attrs[\"original_id\"] = original_sequence_id\n",
    "\n",
    "    # 4. Append values from csv file\n",
    "    for idx, embedding in reduced_output_embeddings_file.items():\n",
    "        original_sequence_id = reduced_embeddings_one_hot_file[idx].attrs[\"original_id\"]\n",
    "        appendix = values_dict[original_sequence_id]\n",
    "        reduced_output_embeddings_file[idx].resize((one_hot_dim + len(appendix)), axis=0)\n",
    "        reduced_output_embeddings_file[idx][-len(appendix):] = np.array(appendix)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ID: Embedding} in biotrainer format:\n",
      " {'Seq3': <HDF5 dataset \"0\": shape (26,), type \"<f4\">, 'Seq4': <HDF5 dataset \"1\": shape (26,), type \"<f4\">, 'Seq1': <HDF5 dataset \"2\": shape (26,), type \"<f4\">, 'Seq2': <HDF5 dataset \"3\": shape (26,), type \"<f4\">}\n"
     ]
    }
   ],
   "source": [
    "# Verify merged file\n",
    "reduced_combined_embeddings_file = h5py.File(reduced_output_embeddings_path, 'r', rdcc_nbytes=1024 ** 2 * 4000,\n",
    "                                             rdcc_nslots=1e7)\n",
    "\n",
    "for idx, embedding in reduced_combined_embeddings_file.items():\n",
    "    original_sequence_id = reduced_combined_embeddings_file[idx].attrs[\"original_id\"]\n",
    "    appendix = values_dict[original_sequence_id]\n",
    "    assert embedding.shape[0] == one_hot_dim + len(appendix), \"New dimension is not correct\"\n",
    "    assert not (embedding[one_hot_dim:] - np.array(appendix)).all(), \"Values not correctly merged\"\n",
    "\n",
    "# Show embeddings in internal biotrainer format\n",
    "id2emb = {reduced_combined_embeddings_file[idx].attrs[\"original_id\"]: embedding for (idx, embedding) in\n",
    "          reduced_combined_embeddings_file.items()}\n",
    "print(\"{ID: Embedding} in biotrainer format:\\n\", id2emb)\n",
    "\n",
    "reduced_combined_embeddings_file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}