{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This notebook demonstrates how to apply nucleotide augmentation to existing sequence embeddings\n",
    "# Original paper: https://www.biorxiv.org/content/10.1101/2022.03.08.483422v1.full.pdf\n",
    "\n",
    "# We will use embeddings on a sequence level (reduced embeddings)\n",
    "# We concatenate to existing one_hot_encoding embeddings\n",
    "# The sequences have ids [Seq1, Seq2, Seq3, Seq4], like the example for sequence_to_class\n",
    "# The resulting sequences will be flattened (taking the mean) into one vector, e.g. [0,0,0,1]+[1,0,0,0]=[0.5,0,0,0.5]\n",
    "\n",
    "import re\n",
    "import h5py\n",
    "\n",
    "from Bio import SeqIO\n",
    "from nt_augment import nucleotide_seq_to_unigram_vector, nucleotide_seq_to_trigram_vector, aa_to_nt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Set hyperparameters for whole file\n",
    "# Number of generated nucleotide seqs (aug_factor * train_seqs + val_seqs + test_seqs = n_new_seqs)\n",
    "aug_factor = 3\n",
    "# nucleotide_seq_to_unigram_vector for unigrams (len 4), nucleotide_seq_to_trigram_vector for trigrams (len 64)\n",
    "ngram_function = [nucleotide_seq_to_unigram_vector, nucleotide_seq_to_trigram_vector][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Load existing reduced embedding files\n",
    "reduced_embeddings_one_hot_path = \"../example_files/reduced_embeddings_file_one_hot_encoding.h5\"\n",
    "reduced_embeddings_one_hot_file = h5py.File(reduced_embeddings_one_hot_path, 'r', rdcc_nbytes=1024 ** 2 * 4000,\n",
    "                                            rdcc_nslots=1e7)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Read FASTA file with AA sequences\n",
    "sequences_path = \"../example_files/sequences.fasta\"\n",
    "fasta_result = list(SeqIO.parse(sequences_path, \"fasta\"))\n",
    "id_to_seq_and_target_dict = {}\n",
    "val_or_test_seq_ids = []\n",
    "for sequence in fasta_result:\n",
    "    for key, value in re.findall(r\"([A-Z_]+)=(-?[A-z0-9]+[.0-9]*)\", sequence.description):\n",
    "        if key == \"TARGET\":\n",
    "            id_to_seq_and_target_dict[str(sequence.id)] = (sequence.seq, value)\n",
    "        if key == \"SET\" and value.lower() == \"test\":\n",
    "            val_or_test_seq_ids.append(str(sequence.id))\n",
    "        elif key == \"VALIDATION\" and value.capitalize() == \"True\":\n",
    "            val_or_test_seq_ids.append(str(sequence.id))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Read FASTA content to write a new FASTA file later\n",
    "seq_lines_dict = {}\n",
    "with open(sequences_path, \"r\") as fasta_file:\n",
    "    lines = fasta_file.readlines()\n",
    "    for i, line in enumerate(lines):\n",
    "        if \">\" in line:\n",
    "            seq_id = line.split(\" \")[0].replace(\">\", \"\")\n",
    "            seq_lines_dict[seq_id] = (line, lines[i+1] if lines[i+1][-1] == \"\\n\" else lines[i+1] + \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Seq1': ['TCTGAACAATGGGAAAATTGTGAA', 'TCTGAACAATGGGAAAATTGTGAG', 'TCTGAACAATGGGAAAATTGCGAA'], 'Seq2': ['CCTCGTACTGAAATTAAT', 'CCTCGTACTGAAATTAAC', 'CCTCGTACTGAAATCAAT'], 'Seq3': ['TCTGAACAAGTTGAAAATTGTGAACCTCGTACTGAAATT', 'TCTGAACAAGTTGAAAATTGTGAACCTCGTACTGAAATC', 'TCTGAACAAGTTGAAAATTGTGAACCTCGTACTGAAATA'], 'Seq4': ['CCTCGTACTGAAATTAATTCTGAACAATGGGAAAATTGTGAA', 'CCTCGTACTGAAATTAATTCTGAACAATGGGAAAATTGTGAG', 'CCTCGTACTGAAATTAATTCTGAACAATGGGAAAATTGCGAA']}\n"
     ]
    }
   ],
   "source": [
    "nt_result, _ = aa_to_nt(id_to_seq_and_target_dict, aug_factor=aug_factor)\n",
    "print(nt_result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Append nucleotide vector to existing embedding\n",
    "# Add values to new file:\n",
    "# 1. Create a new file\n",
    "output_embeddings_path = \"enhanced_nucleotide_embeddings.h5\"\n",
    "output_sequences_path = \"enhanced_sequences.fasta\"\n",
    "# 2. Get embedding dimension\n",
    "one_hot_dim = reduced_embeddings_one_hot_file[\"0\"].shape[0]\n",
    "\n",
    "with h5py.File(output_embeddings_path, \"w\") as output_embeddings_file, open(output_sequences_path, \"w\") as output_sequences_file:\n",
    "    augment_id = 0\n",
    "    for idx, embedding in reduced_embeddings_one_hot_file.items():\n",
    "        original_sequence_id = reduced_embeddings_one_hot_file[idx].attrs[\"original_id\"]\n",
    "        # Only augment train sequences aug_factor-times\n",
    "        # Note that Val and Test sequences also get the extended embedding (but only for one sequence)\n",
    "        add_n_times = aug_factor if original_sequence_id not in val_or_test_seq_ids else 1\n",
    "        for nt in range(add_n_times):\n",
    "            # 3. Calculate flattened nucleotide ngram vector\n",
    "            nt_appendix = ngram_function(nt_result[original_sequence_id][nt])\n",
    "            appendix_dim = len(nt_appendix)  # 4\n",
    "            # 4. Save one_hot_encoding values in new file with extended shape\n",
    "            output_embeddings_file.create_dataset(str(augment_id), data=embedding, compression=\"gzip\", chunks=True,\n",
    "                                                  maxshape=(one_hot_dim + appendix_dim))\n",
    "            # 5. Append the ngram vector\n",
    "            output_embeddings_file[str(augment_id)].resize((one_hot_dim + appendix_dim), axis=0)\n",
    "            output_embeddings_file[str(augment_id)][-appendix_dim:] = nt_appendix\n",
    "            # 6. Set new original sequence id (e.g. Seq1 -> Seq1I)\n",
    "            augmented_sequence_id = original_sequence_id + \"I\" * (nt + 1)\n",
    "            output_embeddings_file[str(augment_id)].attrs[\"original_id\"] = augmented_sequence_id\n",
    "            # 7. Write sequence with augmented_sequence_id to new fasta file\n",
    "            header = seq_lines_dict[original_sequence_id][0].replace(original_sequence_id, augmented_sequence_id)\n",
    "            seq = seq_lines_dict[original_sequence_id][1]\n",
    "            output_sequences_file.write(header)\n",
    "            output_sequences_file.write(seq)\n",
    "\n",
    "            augment_id += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ID: Embedding} in biotrainer format:\n",
      " {'Seq3I': <HDF5 dataset \"0\": shape (25,), type \"<f4\">, 'Seq4I': <HDF5 dataset \"1\": shape (25,), type \"<f4\">, 'Seq1I': <HDF5 dataset \"2\": shape (25,), type \"<f4\">, 'Seq1II': <HDF5 dataset \"3\": shape (25,), type \"<f4\">, 'Seq1III': <HDF5 dataset \"4\": shape (25,), type \"<f4\">, 'Seq2I': <HDF5 dataset \"5\": shape (25,), type \"<f4\">}\n"
     ]
    }
   ],
   "source": [
    "# Verify new file\n",
    "combined_embeddings_file = h5py.File(output_embeddings_path, 'r')\n",
    "\n",
    "# Show embeddings in internal biotrainer format\n",
    "id2emb = {combined_embeddings_file[idx].attrs[\"original_id\"]: embedding for (idx, embedding) in\n",
    "          combined_embeddings_file.items()}\n",
    "print(\"{ID: Embedding} in biotrainer format:\\n\", id2emb)\n",
    "\n",
    "combined_embeddings_file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}