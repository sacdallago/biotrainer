{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# This notebook demonstrates how to add arbitrary numerical values from a csv file to an existing embedding file\n",
    "# We will use embeddings on a sequence level (reduced embeddings)\n",
    "# We concatenate to existing one_hot_encoding embeddings\n",
    "# The sequences have ids [Seq1, Seq2, Seq3, Seq4], like the example for sequence_to_class\n",
    "# TODO!!\n",
    "\n",
    "import h5py\n",
    "from Bio import SeqIO\n",
    "\n",
    "import nt_augment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# Load existing reduced embedding files\n",
    "reduced_embeddings_one_hot_path = \"../example_files/reduced_embeddings_file_one_hot_encoding.h5\"\n",
    "reduced_embeddings_one_hot_file = h5py.File(reduced_embeddings_one_hot_path, 'r', rdcc_nbytes=1024 ** 2 * 4000,\n",
    "                                            rdcc_nslots=1e7)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Seq1': (Seq('SEQWENCE'), 'Glob'), 'Seq2': (Seq('PRTEIN'), 'GlobSP'), 'Seq3': (Seq('SEQVENCEPRTEI'), 'TM'), 'Seq4': (Seq('PRTEINSEQWENCE'), 'TMSP')}\n"
     ]
    }
   ],
   "source": [
    "# Read FASTA file with AA sequences\n",
    "sequences_path = \"../example_files/sequences.fasta\"\n",
    "fasta_result = list(SeqIO.parse(sequences_path, \"fasta\"))\n",
    "id_to_seq_and_target_dict = {}\n",
    "for sequence in fasta_result:\n",
    "    for key, value in re.findall(r\"([A-Z_]+)=(-?[A-z0-9]+[.0-9]*)\", sequence.description):\n",
    "        if key == \"TARGET\":\n",
    "            id_to_seq_and_target_dict[str(sequence.id)] = (sequence.seq, value)\n",
    "\n",
    "print(id_to_seq_and_target_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# Read FASTA content for writing later\n",
    "seq_lines_dict = {}\n",
    "with open(sequences_path, \"r\") as fasta_file:\n",
    "    lines = fasta_file.readlines()\n",
    "    for i, line in enumerate(lines):\n",
    "        if \">\" in line:\n",
    "            seq_id = line.split(\" \")[0].replace(\">\", \"\")\n",
    "            seq_lines_dict[seq_id] = (line, lines[i+1] if lines[i+1][-1] == \"\\n\" else lines[i+1] + \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Seq1': ['TCTGAACAATGGGAAAATTGTGAA', 'TCTGAACAATGGGAAAATTGTGAG', 'TCTGAACAATGGGAAAATTGCGAA'], 'Seq2': ['CCTCGTACTGAAATTAAT', 'CCTCGTACTGAAATTAAC', 'CCTCGTACTGAAATCAAT'], 'Seq3': ['TCTGAACAAGTTGAAAATTGTGAACCTCGTACTGAAATT', 'TCTGAACAAGTTGAAAATTGTGAACCTCGTACTGAAATC', 'TCTGAACAAGTTGAAAATTGTGAACCTCGTACTGAAATA'], 'Seq4': ['CCTCGTACTGAAATTAATTCTGAACAATGGGAAAATTGTGAA', 'CCTCGTACTGAAATTAATTCTGAACAATGGGAAAATTGTGAG', 'CCTCGTACTGAAATTAATTCTGAACAATGGGAAAATTGCGAA']}\n"
     ]
    },
    {
     "data": {
      "text/plain": "\"\\ndata = {}\\ndata['aaseq'] = sequences\\ndata['target'] = targets\\nresult = nt_augment.nt_augmentation(data, final_data_len=20)\\nprint(result)\\n\""
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_factor = 3\n",
    "nt_result, _ = nt_augment.aa_to_nt(id_to_seq_and_target_dict, aug_factor=3)\n",
    "print(nt_result)\n",
    "\"\"\"\n",
    "data = {}\n",
    "data['aaseq'] = sequences\n",
    "data['target'] = targets\n",
    "result = nt_augment.nt_augmentation(data, final_data_len=20)\n",
    "print(result)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# Append to embedding\n",
    "def nucleotide_to_one_hot(nt: str):\n",
    "    return {'A': [1, 0, 0, 0],\n",
    "            'C': [0, 1, 0, 0],\n",
    "            'T': [0, 0, 1, 0],\n",
    "            'G': [0, 0, 0, 1]}[nt]\n",
    "\n",
    "\n",
    "def nucleotide_seq_to_vector(nt_seq: str):\n",
    "    result_list = []\n",
    "    for nt in nt_seq:\n",
    "        one_hot = nucleotide_to_one_hot(nt)\n",
    "        result_list.append(one_hot)\n",
    "    return np.sum(result_list, axis=0) / len(result_list)\n",
    "\n",
    "\n",
    "# Add values to new file:\n",
    "# 1. Create a new file\n",
    "output_embeddings_path = \"enhanced_nucleotide_embeddings.h5\"\n",
    "output_sequences_path = \"enhanced_sequences.fasta\"\n",
    "# 2. Get embedding dimension\n",
    "one_hot_dim = reduced_embeddings_one_hot_file[\"0\"].shape[0]\n",
    "\n",
    "with h5py.File(output_embeddings_path, \"w\") as output_embeddings_file, open(output_sequences_path, \"w\") as output_sequences_file:\n",
    "    # 3. Save one_hot_encoding values in new file with extended shape\n",
    "    augment_id = 0\n",
    "    for idx, embedding in reduced_embeddings_one_hot_file.items():\n",
    "        for nt in range(aug_factor):\n",
    "            original_sequence_id = reduced_embeddings_one_hot_file[idx].attrs[\"original_id\"]\n",
    "            nt_appendix = nucleotide_seq_to_vector(nt_result[original_sequence_id][nt])\n",
    "            appendix_dim = len(nt_appendix)  # 4\n",
    "            output_embeddings_file.create_dataset(str(augment_id), data=embedding, compression=\"gzip\", chunks=True,\n",
    "                                                  maxshape=(one_hot_dim + appendix_dim))\n",
    "            output_embeddings_file[str(augment_id)].resize((one_hot_dim + appendix_dim), axis=0)\n",
    "            output_embeddings_file[str(augment_id)][-appendix_dim:] = nt_appendix\n",
    "            augmented_sequence_id = original_sequence_id + \"I\" * (nt + 1)\n",
    "            output_embeddings_file[str(augment_id)].attrs[\"original_id\"] = augmented_sequence_id\n",
    "            header = seq_lines_dict[original_sequence_id][0].replace(original_sequence_id, augmented_sequence_id)\n",
    "            seq = seq_lines_dict[original_sequence_id][1]\n",
    "            output_sequences_file.write(header)\n",
    "            output_sequences_file.write(seq)\n",
    "            augment_id += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 file \"enhanced_nucleotide_embeddings.h5\" (mode r)>\n",
      "{ID: Embedding} in biotrainer format:\n",
      " {'Seq3I': <HDF5 dataset \"0\": shape (25,), type \"<f4\">, 'Seq3II': <HDF5 dataset \"1\": shape (25,), type \"<f4\">, 'Seq2II': <HDF5 dataset \"10\": shape (25,), type \"<f4\">, 'Seq2III': <HDF5 dataset \"11\": shape (25,), type \"<f4\">, 'Seq3III': <HDF5 dataset \"2\": shape (25,), type \"<f4\">, 'Seq4I': <HDF5 dataset \"3\": shape (25,), type \"<f4\">, 'Seq4II': <HDF5 dataset \"4\": shape (25,), type \"<f4\">, 'Seq4III': <HDF5 dataset \"5\": shape (25,), type \"<f4\">, 'Seq1I': <HDF5 dataset \"6\": shape (25,), type \"<f4\">, 'Seq1II': <HDF5 dataset \"7\": shape (25,), type \"<f4\">, 'Seq1III': <HDF5 dataset \"8\": shape (25,), type \"<f4\">, 'Seq2I': <HDF5 dataset \"9\": shape (25,), type \"<f4\">}\n"
     ]
    }
   ],
   "source": [
    "# Verify merged file\n",
    "combined_embeddings_file = h5py.File(output_embeddings_path, 'r', rdcc_nbytes=1024 ** 2 * 4000,\n",
    "                                     rdcc_nslots=1e7)\n",
    "print(combined_embeddings_file)\n",
    "# Show embeddings in internal biotrainer format\n",
    "id2emb = {combined_embeddings_file[idx].attrs[\"original_id\"]: embedding for (idx, embedding) in\n",
    "          combined_embeddings_file.items()}\n",
    "print(\"{ID: Embedding} in biotrainer format:\\n\", id2emb)\n",
    "\n",
    "combined_embeddings_file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}