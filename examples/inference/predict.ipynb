{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biotrainer Inference example\n",
    "\n",
    "After having trained a model, you can use the out.yml and an input sequence file to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-07-10T13:11:24.569325Z",
     "start_time": "2024-07-10T13:11:24.565739Z"
    }
   },
   "source": "from biotrainer.inference import Inferencer",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-07-10T13:11:25.114537Z",
     "start_time": "2024-07-10T13:11:25.079838Z"
    }
   },
   "source": [
    "out_file_path = '../residue_to_class/output/out.yml'\n",
    "inferencer, iom = Inferencer.create_from_out_file(out_file_path=out_file_path)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ../residue_to_class/output/out.yml..\n",
      "Reading checkpoint(s) from directory: ../residue_to_class/output/CNN/one_hot_encoding..\n",
      "Got 1 split(s): hold_out\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebie/.cache/pypoetry/virtualenvs/biotrainer-_BxfB8Sv-py3.11/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `SpearmanCorrcoef` will save all targets and predictions in the buffer. For large datasets, this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to create the embeddings for the sequences we are interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2023-06-27T09:07:41.281958854Z",
     "start_time": "2023-06-27T09:07:35.047007129Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebie/.cache/pypoetry/virtualenvs/biotrainer-_BxfB8Sv-py3.9/lib/python3.9/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/sebie/.cache/pypoetry/virtualenvs/biotrainer-_BxfB8Sv-py3.9/lib/python3.9/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/sebie/.cache/pypoetry/virtualenvs/biotrainer-_BxfB8Sv-py3.9/lib/python3.9/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/sebie/.cache/pypoetry/virtualenvs/biotrainer-_BxfB8Sv-py3.9/lib/python3.9/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "from biotrainer.embedders import OneHotEncodingEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T09:07:42.916680038Z",
     "start_time": "2023-06-27T09:07:42.914670992Z"
    }
   },
   "outputs": [],
   "source": [
    "embedder = OneHotEncodingEmbedder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2023-06-27T09:07:42.957685845Z",
     "start_time": "2023-06-27T09:07:42.920226360Z"
    }
   },
   "outputs": [],
   "source": [
    "sequences = [\n",
    "    \"PROVTEIN\",\n",
    "    \"SEQVENCESEQVENCE\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2023-06-27T09:07:42.962420068Z",
     "start_time": "2023-06-27T09:07:42.954013556Z"
    }
   },
   "outputs": [],
   "source": [
    "embeddings = list(embedder.embed_many(sequences))\n",
    "# Note that for per-sequence embeddings, you would have to reduce the embeddings now:\n",
    "# embeddings = [[embedder.reduce_per_protein(embedding)] for embedding in embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2023-06-27T09:07:46.304416417Z",
     "start_time": "2023-06-27T09:07:44.652947105Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = inferencer.from_embeddings(embeddings, split_name=\"hold_out\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2023-06-27T09:07:46.304941054Z",
     "start_time": "2023-06-27T09:07:46.304192031Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROVTEIN\n",
      "FFFDFDFF\n",
      "SEQVENCESEQVENCE\n",
      "FFEFFFFFDEFFFFEF\n"
     ]
    }
   ],
   "source": [
    "for sequence, prediction in zip(sequences, predictions[\"mapped_predictions\"].values()):\n",
    "    print(sequence)\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**If your model uses dropout, you can also use inferencer.from_embeddings_with_monte_carlo_dropout to get the predictions with monte-carlo dropout. This is a method to quantify the uncertainty within your model.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T09:07:46.305117824Z",
     "start_time": "2023-06-27T09:07:46.304635933Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions_mcd = inferencer.from_embeddings_with_monte_carlo_dropout(embeddings, n_forward_passes=30, confidence_level=0.05, split_name=\"hold_out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residue: P, MCD Prediction: {'prediction': 'F', 'mcd_mean': tensor([0.1805, 0.2024, 0.2090, 0.2164, 0.1918], device='cuda:0'), 'mcd_lower_bound': tensor([0.1795, 0.2012, 0.2075, 0.2155, 0.1906], device='cuda:0'), 'mcd_upper_bound': tensor([0.1814, 0.2037, 0.2104, 0.2173, 0.1929], device='cuda:0')}\n",
      "Residue: R, MCD Prediction: {'prediction': 'F', 'mcd_mean': tensor([0.1854, 0.2050, 0.2000, 0.2168, 0.1927], device='cuda:0'), 'mcd_lower_bound': tensor([0.1841, 0.2032, 0.1985, 0.2156, 0.1916], device='cuda:0'), 'mcd_upper_bound': tensor([0.1868, 0.2068, 0.2016, 0.2181, 0.1939], device='cuda:0')}\n",
      "Residue: O, MCD Prediction: {'prediction': 'F', 'mcd_mean': tensor([0.1977, 0.2039, 0.1943, 0.2077, 0.1964], device='cuda:0'), 'mcd_lower_bound': tensor([0.1967, 0.2023, 0.1930, 0.2057, 0.1951], device='cuda:0'), 'mcd_upper_bound': tensor([0.1988, 0.2054, 0.1955, 0.2097, 0.1978], device='cuda:0')}\n",
      "Residue: V, MCD Prediction: {'prediction': 'D', 'mcd_mean': tensor([0.1929, 0.2117, 0.2044, 0.1997, 0.1912], device='cuda:0'), 'mcd_lower_bound': tensor([0.1914, 0.2096, 0.2025, 0.1982, 0.1898], device='cuda:0'), 'mcd_upper_bound': tensor([0.1944, 0.2138, 0.2063, 0.2013, 0.1927], device='cuda:0')}\n",
      "Residue: T, MCD Prediction: {'prediction': 'D', 'mcd_mean': tensor([0.1891, 0.2078, 0.1957, 0.2069, 0.2006], device='cuda:0'), 'mcd_lower_bound': tensor([0.1877, 0.2061, 0.1941, 0.2053, 0.1990], device='cuda:0'), 'mcd_upper_bound': tensor([0.1904, 0.2094, 0.1973, 0.2085, 0.2022], device='cuda:0')}\n",
      "Residue: E, MCD Prediction: {'prediction': 'D', 'mcd_mean': tensor([0.2007, 0.2036, 0.1985, 0.2013, 0.1959], device='cuda:0'), 'mcd_lower_bound': tensor([0.1991, 0.2020, 0.1968, 0.1997, 0.1945], device='cuda:0'), 'mcd_upper_bound': tensor([0.2023, 0.2052, 0.2002, 0.2029, 0.1973], device='cuda:0')}\n",
      "Residue: I, MCD Prediction: {'prediction': 'F', 'mcd_mean': tensor([0.1918, 0.2032, 0.2093, 0.2118, 0.1839], device='cuda:0'), 'mcd_lower_bound': tensor([0.1904, 0.2016, 0.2075, 0.2098, 0.1828], device='cuda:0'), 'mcd_upper_bound': tensor([0.1932, 0.2049, 0.2112, 0.2139, 0.1849], device='cuda:0')}\n",
      "Residue: N, MCD Prediction: {'prediction': 'F', 'mcd_mean': tensor([0.1857, 0.1887, 0.2026, 0.2268, 0.1962], device='cuda:0'), 'mcd_lower_bound': tensor([0.1839, 0.1874, 0.2013, 0.2254, 0.1952], device='cuda:0'), 'mcd_upper_bound': tensor([0.1874, 0.1901, 0.2039, 0.2282, 0.1972], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "# Show predictions for first sequence:\n",
    "for idx, residue in enumerate(sequences[0]):\n",
    "    print(f\"Residue: {residue}, MCD Prediction: {predictions_mcd['0'][idx]}\")\n",
    "    # prediction: Class prediction based on the mean over 30 forward passes\n",
    "    # mcd_mean: Average over 30 forward passes\n",
    "    # mcd_lower_bound: Lower bound of confidence interval using normal distribution with the given confidence level\n",
    "    # mcd_upper_bound: Upper bound of confidence interval using normal distribution with the given confidence level"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T09:07:46.316801787Z",
     "start_time": "2023-06-27T09:07:46.304832997Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**To compute error margins for your model, you can use the bootstrapping functionality. You must provide the according targets for this. In this example, we will use some arbitrary values.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': {'mean': 1.5665744543075562, 'error': 0.000751411949750036}, 'accuracy': {'mean': 0.7902777791023254, 'error': 0.036831799894571304}, 'macro-precision': {'mean': 0.4960740804672241, 'error': 0.03868114948272705}, 'micro-precision': {'mean': 0.7902777791023254, 'error': 0.036831799894571304}, '- precision class 0': {'mean': 0.0, 'error': 0.0}, '- precision class 1': {'mean': 1.0, 'error': 0.0}, '- precision class 2': {'mean': 0.7333333492279053, 'error': 0.16094747185707092}, '- precision class 3': {'mean': 0.7470370531082153, 'error': 0.03337482735514641}, '- precision class 4': {'mean': 0.0, 'error': 0.0}, 'macro-recall': {'mean': 0.4265555441379547, 'error': 0.03321339190006256}, 'micro-recall': {'mean': 0.7902777791023254, 'error': 0.036831799894571304}, '- recall class 0': {'mean': 0.0, 'error': 0.0}, '- recall class 1': {'mean': 0.8027777671813965, 'error': 0.0485801137983799}, '- recall class 2': {'mean': 0.39666667580604553, 'error': 0.08839632570743561}, '- recall class 3': {'mean': 0.9333333373069763, 'error': 0.04023686796426773}, '- recall class 4': {'mean': 0.0, 'error': 0.0}, 'macro-f1_score': {'mean': 0.44566452503204346, 'error': 0.03437119722366333}, 'micro-f1_score': {'mean': 0.7902777791023254, 'error': 0.036831799894571304}, '- f1_score class 0': {'mean': 0.0, 'error': 0.0}, '- f1_score class 1': {'mean': 0.8847619295120239, 'error': 0.028728071600198746}, '- f1_score class 2': {'mean': 0.5138888955116272, 'error': 0.11350579559803009}, '- f1_score class 3': {'mean': 0.8296717405319214, 'error': 0.03615475073456764}, '- f1_score class 4': {'mean': 0.0, 'error': 0.0}, 'spearmans-corr-coeff': {'mean': 0.6839829683303833, 'error': 0.04194672778248787}, 'matthews-corr-coeff': {'mean': 0.6354082226753235, 'error': 0.060555633157491684}}\n"
     ]
    }
   ],
   "source": [
    "targets = [\"FDFDFDFE\", \"FFEFEEFFDEFFFFEF\"]\n",
    "bootstrapping_result = inferencer.from_embeddings_with_bootstrapping(embeddings, targets, split_name=\"hold_out\", iterations=30, confidence_level=0.05, seed=42)\n",
    "print(bootstrapping_result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T09:08:36.252867891Z",
     "start_time": "2023-06-27T09:08:35.814330253Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T09:07:52.267112340Z",
     "start_time": "2023-06-27T09:07:52.263968091Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
