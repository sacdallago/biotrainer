auto_resume: false
batch_size: 128
biotrainer_version: 0.6.0
class_int_to_string:
  0: Glob
  1: GlobSP
  2: TM
  3: TMSP
class_str_to_int:
  Glob: 0
  GlobSP: 1
  TM: 2
  TMSP: 3
cross_validation_config:
  choose_by: loss
  method: hold_out
device: cuda
elapsed_time_total: 2.8207157149990962
embedder_name: one_hot_encoding
embeddings_file: 
  /home/sebie/PycharmProjects/biotrainerFork/examples/residues_to_class/output/residues_to_class/one_hot_encoding/embeddings/embeddings_file.h5
epsilon: 0.001
learning_rate: 0.001
log_dir: 
  /home/sebie/PycharmProjects/biotrainerFork/examples/residues_to_class/output/LightAttention/one_hot_encoding
loss_choice: cross_entropy_loss
model_choice: LightAttention
n_classes: 4
n_features: 21
n_testing_ids: 2
num_epochs: 200
optimizer_choice: adam
output_dir: /home/sebie/PycharmProjects/biotrainerFork/examples/residues_to_class/output
patience: 10
protocol: residues_to_class
sanity_check: true
save_split_ids: false
seed: 42
sequence_file: 
  /home/sebie/PycharmProjects/biotrainerFork/examples/residues_to_class/sequences.fasta
shuffle: true
split_results:
  hold_out:
    elapsed_time: 1.8921789590003755
    end_time: 2023-06-29 15:02:51.962149
    n_free_parameters: 9552
    n_training_ids: 2
    n_validation_ids: 2
    split_hyper_params: {}
    start_time: 2023-06-29 15:02:50.069966
    training_iteration_result_best_epoch:
      epoch: 17
      training:
        '- f1_score class 0': 0.0
        '- f1_score class 1': 1.0
        '- f1_score class 2': 0.0
        '- f1_score class 3': 0.0
        '- precission class 0': 0.0
        '- precission class 1': 1.0
        '- precission class 2': 0.0
        '- precission class 3': 0.0
        '- recall class 0': 0.0
        '- recall class 1': 1.0
        '- recall class 2': 0.0
        '- recall class 3': 0.0
        accuracy: 0.5
        loss: 1.1131129264831543
        macro-f1_score: 0.25
        macro-precision: 0.25
        macro-recall: 0.25
        matthews-corr-coeff: 0.5
        micro-f1_score: 0.5
        micro-precision: 0.5
        micro-recall: 0.5
        spearmans-corr-coeff: -0.9999959468841553
      validation:
        '- f1_score class 0': 0.0
        '- f1_score class 1': 1.0
        '- f1_score class 2': 1.0
        '- f1_score class 3': 0.0
        '- precission class 0': 0.0
        '- precission class 1': 1.0
        '- precission class 2': 1.0
        '- precission class 3': 0.0
        '- recall class 0': 0.0
        '- recall class 1': 1.0
        '- recall class 2': 1.0
        '- recall class 3': 0.0
        accuracy: 1.0
        loss: 0.8826410174369812
        macro-f1_score: 0.5
        macro-precision: 0.5
        macro-recall: 0.5
        matthews-corr-coeff: 1.0
        micro-f1_score: 1.0
        micro-precision: 1.0
        micro-recall: 1.0
        spearmans-corr-coeff: 0.9999959468841553
test_iterations_results:
  metrics:
    '- f1_score class 0': 0.0
    '- f1_score class 1': 0.0
    '- f1_score class 2': 0.0
    '- f1_score class 3': 0.0
    '- precission class 0': 0.0
    '- precission class 1': 0.0
    '- precission class 2': 0.0
    '- precission class 3': 0.0
    '- recall class 0': 0.0
    '- recall class 1': 0.0
    '- recall class 2': 0.0
    '- recall class 3': 0.0
    accuracy: 0.0
    loss: 1.4794641733169556
    macro-f1_score: 0.0
    macro-precision: 0.0
    macro-recall: 0.0
    matthews-corr-coeff: 0
    micro-f1_score: 0.0
    micro-precision: 0.0
    micro-recall: 0.0
    spearmans-corr-coeff: 0.0
  test_baselines: {}
use_class_weights: false
